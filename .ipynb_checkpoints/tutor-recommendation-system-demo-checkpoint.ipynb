{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ntry:\n    import tensorflow as tf\n    from tensorflow import keras\n    TF_AVAILABLE = True\nexcept Exception:\n    TF_AVAILABLE = False\n    tf = None\n    keras = None\n\nimport lightgbm as lgb\n\n# --------------------------\n# 1) DATA (from parsed PDF)\n# --------------------------\n# We use the same small data we discussed earlier (manually constructed)\n# This guarantees reproducibility of the demo.\nstudents = pd.DataFrame([\n    {\"student_id\":\"S1\",\"name\":\"Daniel\",\"hobbies\":\"gaming, music\",\"learning_language\":\"English\",\"programming_focus\":\"Python\",\"level\":\"beginner\"},\n    {\"student_id\":\"S2\",\"name\":\"Aisha\",\"hobbies\":\"reading, chess\",\"learning_language\":\"French\",\"programming_focus\":\"JavaScript\",\"level\":\"beginner\"},\n    {\"student_id\":\"S3\",\"name\":\"Kelvin\",\"hobbies\":\"football, coding\",\"learning_language\":\"Spanish\",\"programming_focus\":\"Python\",\"level\":\"intermediate\"},\n    {\"student_id\":\"S4\",\"name\":\"Maria\",\"hobbies\":\"art, movies\",\"learning_language\":\"English\",\"programming_focus\":\"Java\",\"level\":\"beginner\"},\n    {\"student_id\":\"S5\",\"name\":\"Zainab\",\"hobbies\":\"music, blogging\",\"learning_language\":\"German\",\"programming_focus\":\"Python\",\"level\":\"advanced\"},\n    {\"student_id\":\"S6\",\"name\":\"Chidi\",\"hobbies\":\"coding, robotics\",\"learning_language\":\"French\",\"programming_focus\":\"C++\",\"level\":\"intermediate\"},\n    {\"student_id\":\"S7\",\"name\":\"Fatima\",\"hobbies\":\"fashion, makeup\",\"learning_language\":\"English\",\"programming_focus\":\"JavaScript\",\"level\":\"beginner\"},\n    {\"student_id\":\"S8\",\"name\":\"John\",\"hobbies\":\"gaming, fitness\",\"learning_language\":\"Spanish\",\"programming_focus\":\"Python\",\"level\":\"intermediate\"},\n    {\"student_id\":\"S9\",\"name\":\"Leah\",\"hobbies\":\"reading, k-drama\",\"learning_language\":\"Korean\",\"programming_focus\":\"JavaScript\",\"level\":\"beginner\"},\n    {\"student_id\":\"S10\",\"name\":\"Emmanuel\",\"hobbies\":\"robotics, coding\",\"learning_language\":\"English\",\"programming_focus\":\"Rust\",\"level\":\"advanced\"}\n])\n\ntutors = pd.DataFrame([\n    {\"tutor_id\":\"T1\",\"name\":\"Mr. Smith\",\"expertise_language\":\"English\",\"programming_specialty\":\"Python\",\"teaching_style\":\"structured\",\"hobbies\":\"gaming\"},\n    {\"tutor_id\":\"T2\",\"name\":\"Ms. Claire\",\"expertise_language\":\"French\",\"programming_specialty\":\"JavaScript\",\"teaching_style\":\"interactive\",\"hobbies\":\"reading\"},\n    {\"tutor_id\":\"T3\",\"name\":\"Juan Pablo\",\"expertise_language\":\"Spanish\",\"programming_specialty\":\"Python\",\"teaching_style\":\"conversational\",\"hobbies\":\"football\"},\n    {\"tutor_id\":\"T4\",\"name\":\"Linda\",\"expertise_language\":\"English\",\"programming_specialty\":\"Java\",\"teaching_style\":\"project-based\",\"hobbies\":\"art\"},\n    {\"tutor_id\":\"T5\",\"name\":\"Hans\",\"expertise_language\":\"German\",\"programming_specialty\":\"Python\",\"teaching_style\":\"structured\",\"hobbies\":\"blogging\"},\n    {\"tutor_id\":\"T6\",\"name\":\"Pierre\",\"expertise_language\":\"French\",\"programming_specialty\":\"C++\",\"teaching_style\":\"analytical\",\"hobbies\":\"robotics\"},\n    {\"tutor_id\":\"T7\",\"name\":\"Yvonne\",\"expertise_language\":\"English\",\"programming_specialty\":\"JavaScript\",\"teaching_style\":\"interactive\",\"hobbies\":\"fashion\"},\n    {\"tutor_id\":\"T8\",\"name\":\"Carlos\",\"expertise_language\":\"Spanish\",\"programming_specialty\":\"Python\",\"teaching_style\":\"hands-on\",\"hobbies\":\"fitness\"},\n    {\"tutor_id\":\"T9\",\"name\":\"Min-ji\",\"expertise_language\":\"Korean\",\"programming_specialty\":\"JavaScript\",\"teaching_style\":\"visual\",\"hobbies\":\"k-drama\"},\n    {\"tutor_id\":\"T10\",\"name\":\"Adrian\",\"expertise_language\":\"English\",\"programming_specialty\":\"Rust\",\"teaching_style\":\"advanced-concepts\",\"hobbies\":\"coding\"}\n])\n\n# Small helper to tokenize hobbies -> set for overlap detection\ndef tokenize(text):\n    return set([t.strip().lower() for t in text.split(\",\") if t.strip()])\n\nstudents['hobby_set'] = students['hobbies'].apply(tokenize)\ntutors['hobby_set'] = tutors['hobbies'].apply(tokenize)\n\n# Teaching-style preferences (pedagogical prior)\nlevel_style_preference = {\n    \"beginner\": {\"structured\", \"interactive\", \"visual\"},\n    \"intermediate\": {\"hands-on\", \"conversational\", \"project-based\", \"interactive\"},\n    \"advanced\": {\"advanced-concepts\", \"analytical\", \"project-based\"}\n}\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:58:55.743199Z","iopub.execute_input":"2025-11-21T10:58:55.743519Z","iopub.status.idle":"2025-11-21T10:59:05.248184Z","shell.execute_reply.started":"2025-11-21T10:58:55.743494Z","shell.execute_reply":"2025-11-21T10:59:05.246858Z"},"editable":false},"outputs":[{"name":"stderr","text":"2025-11-21 10:58:57.309263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763722737.337665    2828 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763722737.346407    2828 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"# 2) PSEUDO-LABELS (heuristic)\n# --------------------------\n# We use the same interpretable heuristic from before to create integer relevance labels.\n# Why? Because real labels (student ratings, accepts) were not provided. Pseudo-labels\n# let the ML model learn the heuristic pattern and generalize.\ndef heuristic_score(student_row, tutor_row):\n    score = 0\n    if student_row[\"learning_language\"].lower() == tutor_row[\"expertise_language\"].lower():\n        score += 3\n    if student_row[\"programming_focus\"].lower() == tutor_row[\"programming_specialty\"].lower():\n        score += 4\n    score += len(student_row['hobby_set'].intersection(tutor_row['hobby_set']))\n    if tutor_row[\"teaching_style\"].lower() in level_style_preference[student_row[\"level\"]]:\n        score += 2\n    return score\n\n# Build pairwise dataset: for each student, one row per tutor (this is how ranking datasets are usually framed)\npair_rows = []\nfor _, s in students.iterrows():\n    for _, t in tutors.iterrows():\n        pair_rows.append({\n            \"student_id\": s[\"student_id\"],\n            \"tutor_id\": t[\"tutor_id\"],\n            \"language_match\": int(s[\"learning_language\"].lower() == t[\"expertise_language\"].lower()),\n            \"programming_match\": int(s[\"programming_focus\"].lower() == t[\"programming_specialty\"].lower()),\n            \"hobby_overlap\": len(s['hobby_set'].intersection(t['hobby_set'])),\n            \"teaching_style_match\": int(t[\"teaching_style\"].lower() in level_style_preference[s[\"level\"]]),\n            \"student_level\": s[\"level\"],\n            \"student_prog\": s[\"programming_focus\"],\n            \"tutor_prog\": t[\"programming_specialty\"],\n            \"label\": heuristic_score(s, t)   # integer relevance label\n        })\n\ndf = pd.DataFrame(pair_rows)\n\n# Save pairwise dataset for inspection / reproducibility\nos.makedirs(\"/kaggle/working/model_outputs\", exist_ok=True)\ndf.to_csv(\"/kaggle/working/model_outputs/pairwise_dataset.csv\", index=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:59:05.250321Z","iopub.execute_input":"2025-11-21T10:59:05.251310Z","iopub.status.idle":"2025-11-21T10:59:05.279076Z","shell.execute_reply.started":"2025-11-21T10:59:05.251275Z","shell.execute_reply":"2025-11-21T10:59:05.277841Z"},"editable":false},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --------------------------\n# 3) FEATURE ENCODING\n# --------------------------\n# Use both simple binary/numeric features and small categorical encodings.\n# Label encoding for small categorical variables is sufficient for tree models; we scale for NN.\nlabel_student_prog = LabelEncoder().fit(df['student_prog'])\nlabel_tutor_prog = LabelEncoder().fit(df['tutor_prog'])\n\ndf['student_prog_le'] = label_student_prog.transform(df['student_prog'])\ndf['tutor_prog_le'] = label_tutor_prog.transform(df['tutor_prog'])\n\nfeatures = [\"language_match\", \"programming_match\", \"hobby_overlap\", \"teaching_style_match\", \"student_prog_le\", \"tutor_prog_le\"]\nX = df[features].values\ny = df['label'].values\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:59:05.280306Z","iopub.execute_input":"2025-11-21T10:59:05.280637Z","iopub.status.idle":"2025-11-21T10:59:05.312732Z","shell.execute_reply.started":"2025-11-21T10:59:05.280612Z","shell.execute_reply":"2025-11-21T10:59:05.311601Z"},"editable":false},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --------------------------\n# 4) TRAIN / TEST SPLIT (grouped by student)\n# --------------------------\n# For ranking you must keep all items of a query (student) together.\nstudent_ids = sorted(df['student_id'].unique())\n# choose train/test splits of students (small demo): first 8 students -> train; last 2 -> test\ntrain_students = student_ids[:8]\ntest_students = student_ids[8:]\n\ntrain_df = df[df['student_id'].isin(train_students)].reset_index(drop=True)\ntest_df  = df[df['student_id'].isin(test_students)].reset_index(drop=True)\n\nX_train = train_df[features].values\ny_train = train_df['label'].values\nX_test  = test_df[features].values\ny_test  = test_df['label'].values\n\n# LightGBM requires group sizes (number of items per query)\ngroup_train = [len(train_df[train_df['student_id']==sid]) for sid in sorted(train_df['student_id'].unique())]\ngroup_test  = [len(test_df[test_df['student_id']==sid]) for sid in sorted(test_df['student_id'].unique())]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:59:05.314698Z","iopub.execute_input":"2025-11-21T10:59:05.315299Z","iopub.status.idle":"2025-11-21T10:59:05.348526Z","shell.execute_reply.started":"2025-11-21T10:59:05.315262Z","shell.execute_reply":"2025-11-21T10:59:05.347418Z"},"editable":false},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --------------------------\n# 5) LIGHTGBM LAMBDARANK (true learning-to-rank)\n# --------------------------\n# Why lambdarank? It optimizes ranking metrics (NDCG) directly and is standard for ranking tasks.\nlgb_train = lgb.Dataset(X_train, label=y_train, group=group_train)\nlgb_val   = lgb.Dataset(X_test,  label=y_test,  group=group_test, reference=lgb_train)\n\nlgb_params = {\n    \"objective\": \"lambdarank\",\n    \"metric\": \"ndcg\",\n    \"ndcg_eval_at\": [1, 3],   # we will monitor NDCG@1 and NDCG@3\n    \"learning_rate\": 0.1,\n    \"num_leaves\": 31,\n    \"min_data_in_leaf\": 1,\n    \"verbosity\": -1,\n    \"seed\": 42\n}\n\n# We use a small number of boosting rounds for the demo. In real data, increase rounds and use CV.\nmodel = lgb.train(lgb_params, lgb_train, valid_sets=[lgb_train, lgb_val], valid_names=['train','valid'],\n                  num_boost_round=100, callbacks=[lgb.early_stopping(stopping_rounds=10)])\n\n# Save the LightGBM model\nmodel.save_model(\"/kaggle/working/model_outputs/lambdarank_model.txt\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:59:05.350255Z","iopub.execute_input":"2025-11-21T10:59:05.350537Z","iopub.status.idle":"2025-11-21T10:59:05.407005Z","shell.execute_reply.started":"2025-11-21T10:59:05.350515Z","shell.execute_reply":"2025-11-21T10:59:05.405389Z"},"editable":false},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 10 rounds\nEarly stopping, best iteration is:\n[3]\ttrain's ndcg@1: 1\ttrain's ndcg@3: 0.997598\tvalid's ndcg@1: 1\tvalid's ndcg@3: 1\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<lightgbm.basic.Booster at 0x79a8d0b3c390>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# --------------------------\n# 6) EVALUATION: NDCG@K (per student)\n# --------------------------\ndef dcg_at_k(rels, k):\n    rels = np.asfarray(rels)[:k]\n    if rels.size == 0:\n        return 0.0\n    discounts = np.log2(np.arange(2, rels.size + 2))\n    return np.sum((2**rels - 1) / discounts)\n\ndef ndcg_at_k(true_rels, pred_scores, k):\n    order = np.argsort(pred_scores)[::-1]\n    sorted_true = np.asarray(true_rels)[order]\n    ideal_sorted = np.sort(true_rels)[::-1]\n    idcg = dcg_at_k(ideal_sorted, k)\n    if idcg == 0:\n        return 0.0\n    return dcg_at_k(sorted_true, k) / idcg\n\ndef evaluate_by_student(model_predict_fn, df_group, k=3):\n    rows = []\n    for sid in sorted(df_group['student_id'].unique()):\n        grp = df_group[df_group['student_id'] == sid]\n        Xg = grp[features].values\n        y_true = grp['label'].values\n        y_pred = model_predict_fn(Xg)\n        ndcg = ndcg_at_k(y_true, y_pred, k)\n        rows.append({\"student_id\": sid, f\"ndcg@{k}\": ndcg})\n    return pd.DataFrame(rows)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:59:05.407868Z","iopub.execute_input":"2025-11-21T10:59:05.408133Z","iopub.status.idle":"2025-11-21T10:59:05.419955Z","shell.execute_reply.started":"2025-11-21T10:59:05.408112Z","shell.execute_reply":"2025-11-21T10:59:05.418857Z"},"editable":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# LightGBM predictions wrapper\nlgb_pred_fn = lambda X: model.predict(X, num_iteration=model.best_iteration)\n\nlgb_eval = evaluate_by_student(lgb_pred_fn, test_df, k=3)\nlgb_mean_ndcg3 = lgb_eval[f\"ndcg@3\"].mean()\n\n# --------------------------\n# 7) NEURAL NETWORK (pointwise ranking / deep regressor)\n# --------------------------\n# A pointwise NN learns to predict the label (relevance score); ranking follows from predicted scores.\nnn_eval = None\nif TF_AVAILABLE:\n    # scale numeric features for NN\n    scaler = StandardScaler().fit(X_train)\n    X_train_scaled = scaler.transform(X_train)\n    X_test_scaled  = scaler.transform(X_test)\n\n    # small MLP regressor (dense layers). We keep it simple due to small dataset.\n    def build_mlp(inp_dim):\n        model_nn = keras.Sequential([\n            keras.layers.Input(shape=(inp_dim,)),\n            keras.layers.Dense(64, activation='relu'),\n            keras.layers.Dense(32, activation='relu'),\n            keras.layers.Dense(1, activation='linear')  # regress relevance\n        ])\n        model_nn.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss='mse')\n        return model_nn\n\n    mlp = build_mlp(X_train_scaled.shape[1])\n    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n    mlp.fit(X_train_scaled, y_train, validation_split=0.1, epochs=200, batch_size=8, callbacks=[es], verbose=0)\n\n    # Save NN and scaler\n    mlp.save(\"/kaggle/working/model_outputs/nn_pointwise_regressor.h5\")\n    import joblib\n    joblib.dump(scaler, \"/kaggle/working/model_outputs/nn_scaler.pkl\")\n\n    # NN predict wrapper\n    nn_pred_fn = lambda X: mlp.predict(scaler.transform(X)).reshape(-1)\n    nn_eval = evaluate_by_student(nn_pred_fn, test_df, k=3)\n    nn_mean_ndcg3 = nn_eval[f\"ndcg@3\"].mean()\nelse:\n    print(\"TensorFlow not installed — skipping neural network training. Install TensorFlow to run the NN block.\")\n\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --------------------------\n# 8) Save evaluation summary and top-K recommendations\n# --------------------------\nsummary = {\n    \"lambdarank_ndcg_by_student\": lgb_eval.to_dict(orient='records'),\n    \"lambdarank_mean_ndcg@3\": float(lgb_mean_ndcg3),\n    \"nn_available\": bool(TF_AVAILABLE)\n}\nif TF_AVAILABLE and nn_eval is not None:\n    summary[\"nn_ndcg_by_student\"] = nn_eval.to_dict(orient='records')\n    summary[\"nn_mean_ndcg@3\"] = float(nn_mean_ndcg3)\n\nwith open(\"/kaggle/working/model_outputs/evaluation_summary.json\", \"w\") as f:\n    json.dump(summary, f, indent=2)\n\n# Save top-3 per test student for each trained model\ndef topk_for_student(model_predict_fn, df_group, k=3):\n    Xg = df_group[features].values\n    preds = model_predict_fn(Xg)\n    df_group = df_group.copy()\n    df_group['pred'] = preds\n    df_group = df_group.sort_values('pred', ascending=False)\n    return df_group.head(k)[['student_id','tutor_id','pred','label']]\n\nall_recs = []\n# LightGBM recs:\nfor sid in sorted(test_df['student_id'].unique()):\n    grp = test_df[test_df['student_id'] == sid]\n    recs = topk_for_student(lgb_pred_fn, grp, k=3)\n    recs['model'] = 'lambdarank'\n    all_recs.append(recs)\n# NN recs if available\nif TF_AVAILABLE and nn_eval is not None:\n    for sid in sorted(test_df['student_id'].unique()):\n        grp = test_df[test_df['student_id'] == sid]\n        recs = topk_for_student(nn_pred_fn, grp, k=3)\n        recs['model'] = 'nn_pointwise'\n        all_recs.append(recs)\n\nif all_recs:\n    recs_df = pd.concat(all_recs, ignore_index=True)\n    recs_df.to_csv(\"/kaggle/working/model_outputs/test_recommendations.csv\", index=False)\n\nprint(\"Finished training. Outputs written to /kaggle/working/model_outputs\")\nprint(os.listdir(\"/kaggle/working/model_outputs\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T10:59:51.734730Z","iopub.execute_input":"2025-11-21T10:59:51.735166Z","iopub.status.idle":"2025-11-21T10:59:51.945573Z","shell.execute_reply.started":"2025-11-21T10:59:51.735139Z","shell.execute_reply":"2025-11-21T10:59:51.944757Z"},"editable":false},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\nFinished training. Outputs written to /kaggle/working/model_outputs\n['pairwise_dataset.csv', 'lambdarank_model.txt', 'test_recommendations.csv', 'nn_scaler.pkl', 'nn_pointwise_regressor.h5', 'evaluation_summary.json']\n","output_type":"stream"}],"execution_count":9}]}